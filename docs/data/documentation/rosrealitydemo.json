{"hierarchy":{"paths":[[]]},"abstract":[{"text":"This pages documents certain insights gained while working on my master thesis - A modular framework for building AR Applications on Apple XR Devices interacting with ROS-based Robots.","type":"text"}],"identifier":{"url":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo","interfaceLanguage":"swift"},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/rosrealitydemo"]}],"metadata":{"modules":[{"name":"Master Thesis Showcase"}],"title":"Master Thesis Showcase","symbolKind":"module","role":"collection","roleHeading":"Framework","externalID":"RosRealityDemo"},"topicSections":[{"anchor":"Topics","identifiers":["doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/RclSwift","doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/RosRealityViewTemplate","doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/RosRealityHelper","doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/RosRealityViewer"]},{"title":"Articles","generated":true,"anchor":"Articles","identifiers":["doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Demos","doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Direct-and-Indirect-Gestures-Handler","doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Fiducial-Marker-Tracker","doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/ROS-Transform-Synchronizer"]}],"primaryContentSections":[{"kind":"content","content":[{"text":"Overview","type":"heading","anchor":"Overview","level":2},{"type":"paragraph","inlineContent":[{"text":"Human Robot Interaction has become more and more with the advent of wide variety of robots and ever evoluing technolgies. In this thesis, I was able to work with the state of art AR\/VR","type":"text"},{"text":" ","type":"text"},{"text":"technology stack from Apple(visionOS) and Manipulators that support ROS2 to develop a framework ground up. There are multiple solutions already exsisting for AR\/VR devices from other OEMs. The popular one being from ","type":"text"},{"identifier":"https:\/\/github.com\/Unity-Technologies\/Unity-Robotics-Hub","isActive":true,"type":"reference"},{"text":". Using this plugin and the newer sdk from Unity would made trivial. In order to leverage the full capabilities of Apple Ecosystem, three main constriants where followed.","type":"text"}]},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Use the Apple’s native development sdk. (Using the swift programming language and Xcode)"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"The framework should be extendable and adhere to Apple Coding Conventions and use only standardized APIs.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Low code possiblities in the context of ROS graph entities."}]}]}],"type":"unorderedList"},{"type":"row","numberOfColumns":2,"columns":[{"content":[{"inlineContent":[{"metadata":{"abstract":[{"type":"text","text":"Framework Specification"}]},"type":"image","identifier":"specification"}],"type":"paragraph"}],"size":1},{"content":[{"inlineContent":[{"type":"image","identifier":"implementation","metadata":{"abstract":[{"type":"text","text":"Implementation"}]}}],"type":"paragraph"}],"size":1}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Check out the following links for the framework’s implementation demos."}]},{"type":"links","style":"compactGrid","items":["doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Demos#Ping-Pong","doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Demos#Robot-Control","doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Demos#Robot-Models","doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Demos#Point-Cloud-2"]},{"type":"heading","anchor":"Possible-Improvements","level":3,"text":"Possible Improvements"},{"type":"paragraph","inlineContent":[{"type":"text","text":"The current implementation of the framework can be consider a starting point and PoC for integrating visionOS devices to the ROS 2 network. Some functionalities that scratched off due to time constraints could be implemented."}]},{"type":"orderedList","items":[{"content":[{"inlineContent":[{"type":"text","text":"Support for DDS or Zenoh based middleware"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Implement more sensor visulations in the RosRealityViewTemplate"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Implement support for URDFS that contain multiple branches.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Implement support for Voice APIs."}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Implement accessiblity to support deverse user groups."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Port RosRealityHelper to visionOS."}]}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Source code is currently accessible only on "},{"type":"reference","identifier":"https:\/\/igm-git.igm.rwth-aachen.de\/projekte\/apple-space","isActive":true},{"type":"text","text":"."}]}],"type":"aside","style":"note","name":"Important "},{"type":"small","inlineContent":[{"type":"text","text":"Credits"}]},{"type":"small","inlineContent":[{"type":"text","text":"Thanks to Mr. Dr. Ing. Markus Schmitz for providing the oppournity to work on this thesis.Thanks to Mr. Robin Heitz, M.Sc. for the screw detection and disassembly workflow."}]}]}],"sections":[],"schemaVersion":{"major":0,"patch":0,"minor":3},"kind":"symbol","references":{"doc://RosRealityDemo/documentation/RosRealityDemo/Demos#Robot-Models":{"abstract":[],"title":"Robot Models","type":"topic","identifier":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Demos#Robot-Models","kind":"section","url":"\/documentation\/rosrealitydemo\/demos#Robot-Models"},"doc://RosRealityDemo/documentation/RosRealityDemo/RosRealityViewTemplate":{"url":"\/documentation\/rosrealitydemo\/rosrealityviewtemplate","type":"topic","kind":"article","identifier":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/RosRealityViewTemplate","title":"RosRealityViewTemplate","role":"article","abstract":[{"text":"A 3D Asset catalog for ROS programms","type":"text"}]},"doc://RosRealityDemo/documentation/RosRealityDemo/Fiducial-Marker-Tracker":{"identifier":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Fiducial-Marker-Tracker","abstract":[{"type":"text","text":"The tracker module takes care of detecting the pose of the fiducial marker placed in user’s environment."}],"role":"article","title":"Fiducial Marker Tracker","url":"\/documentation\/rosrealitydemo\/fiducial-marker-tracker","type":"topic","kind":"article"},"doc://RosRealityDemo/documentation/RosRealityDemo/ROS-Transform-Synchronizer":{"role":"article","url":"\/documentation\/rosrealitydemo\/ros-transform-synchronizer","identifier":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/ROS-Transform-Synchronizer","type":"topic","abstract":[{"type":"text","text":"The robot\/manipulator environment can be described using ROS Transforms. This module explains"},{"type":"text","text":" "},{"type":"text","text":"how to manage ROS Transforms on the Vision OS Application"}],"kind":"article","title":"ROS Transform Synchronizer"},"implementation":{"type":"image","alt":"Framework Implementation","identifier":"implementation","variants":[{"url":"\/images\/RosRealityDemo\/implementation.png","traits":["1x","light"]}]},"doc://RosRealityDemo/documentation/RosRealityDemo/Direct-and-Indirect-Gestures-Handler":{"role":"article","url":"\/documentation\/rosrealitydemo\/direct-and-indirect-gestures-handler","identifier":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Direct-and-Indirect-Gestures-Handler","abstract":[{"text":"This module suggests how to implement a direct and indirect gestures to entities automatically","type":"text"},{"text":" ","type":"text"},{"text":"while reducing the necessary knowledge base when composing scenes using RosRealityViewTemplate.","type":"text"}],"type":"topic","title":"Direct and Indirect Gestures Handler","kind":"article"},"https://github.com/Unity-Technologies/Unity-Robotics-Hub":{"type":"link","identifier":"https:\/\/github.com\/Unity-Technologies\/Unity-Robotics-Hub","titleInlineContent":[{"text":"Unity","type":"text"}],"title":"Unity","url":"https:\/\/github.com\/Unity-Technologies\/Unity-Robotics-Hub"},"doc://RosRealityDemo/documentation/RosRealityDemo/Demos#Point-Cloud-2":{"type":"topic","identifier":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Demos#Point-Cloud-2","abstract":[],"title":"Point Cloud 2","url":"\/documentation\/rosrealitydemo\/demos#Point-Cloud-2","kind":"section"},"doc://RosRealityDemo/documentation/RosRealityDemo":{"role":"collection","identifier":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo","type":"topic","url":"\/documentation\/rosrealitydemo","abstract":[{"text":"This pages documents certain insights gained while working on my master thesis - A modular framework for building AR Applications on Apple XR Devices interacting with ROS-based Robots.","type":"text"}],"kind":"symbol","title":"Master Thesis Showcase"},"doc://RosRealityDemo/documentation/RosRealityDemo/RclSwift":{"kind":"article","url":"\/documentation\/rosrealitydemo\/rclswift","title":"RclSwift","type":"topic","role":"article","identifier":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/RclSwift","abstract":[{"type":"text","text":"ROS Bridge Client Library"}]},"https://igm-git.igm.rwth-aachen.de/projekte/apple-space":{"type":"link","identifier":"https:\/\/igm-git.igm.rwth-aachen.de\/projekte\/apple-space","titleInlineContent":[{"text":"RWTH IGMR Network","type":"text"}],"title":"RWTH IGMR Network","url":"https:\/\/igm-git.igm.rwth-aachen.de\/projekte\/apple-space"},"doc://RosRealityDemo/documentation/RosRealityDemo/Demos#Ping-Pong":{"type":"topic","identifier":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Demos#Ping-Pong","abstract":[],"title":"Ping Pong","url":"\/documentation\/rosrealitydemo\/demos#Ping-Pong","kind":"section"},"doc://RosRealityDemo/documentation/RosRealityDemo/Demos":{"url":"\/documentation\/rosrealitydemo\/demos","type":"topic","title":"Demos","abstract":[{"type":"text","text":"RosRealityViewer Demos"}],"kind":"article","identifier":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Demos","role":"article"},"specification":{"identifier":"specification","alt":"Framework Implementation","variants":[{"url":"\/images\/RosRealityDemo\/specification.png","traits":["1x","light"]}],"type":"image"},"doc://RosRealityDemo/documentation/RosRealityDemo/Demos#Robot-Control":{"type":"topic","identifier":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/Demos#Robot-Control","abstract":[],"title":"Robot Control","url":"\/documentation\/rosrealitydemo\/demos#Robot-Control","kind":"section"},"doc://RosRealityDemo/documentation/RosRealityDemo/RosRealityHelper":{"type":"topic","role":"article","url":"\/documentation\/rosrealitydemo\/rosrealityhelper","abstract":[{"type":"text","text":"ROS Robot Description Converter"}],"title":"RosRealityHelper","kind":"article","identifier":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/RosRealityHelper"},"doc://RosRealityDemo/documentation/RosRealityDemo/RosRealityViewer":{"role":"article","abstract":[{"text":"Apple Vision Pro Application, which can interact with the ROS network and display interactable ROS Entities and Visualization.","type":"text"}],"identifier":"doc:\/\/RosRealityDemo\/documentation\/RosRealityDemo\/RosRealityViewer","type":"topic","kind":"article","url":"\/documentation\/rosrealitydemo\/rosrealityviewer","title":"RosRealityViewer"}}}